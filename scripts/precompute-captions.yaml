name: convert-captions
#image: mosaicml/pytorch_vision:2.0.1_cu118-python3.10-ubuntu20.04 
image: mosaicml/pytorch_vision:1.13.1_cu117-python3.10-ubuntu20.04
compute:
  gpus: 8  # Number of GPUs to use

  ## These configurations are optional
  # cluster: TODO # Name of the cluster to use for this run
  # gpu_type: a100_80gb # Type of GPU to use. We use a100_80gb in our experiments

integrations:
- integration_type: "git_repo"
  git_repo: skylion007/mosaicml-diffusion
  git_branch: skylion007-captionregen-nolats
- integration_type: "wandb"
  project: laion-dataset-regen
  entity: mosaic-ml

command: |
  cd mosaicml-diffusion
  pip install .
  pip uninstall -y mosaicml-streaming
  pip install -U git+https://github.com/mosaicml/streaming.git
  # pip install --upgrade torchmetrics[image]
  # pip install -U mosaicml-streaming composer
  # pip install git+https://github.com/mosaicml/streaming.git@3afa26cc3b36677c86d4ca842afccbdb763b952e
  cd scripts

  BUCKET=1

  composer precompute_captions.py \
    --remote_upload oci://mosaicml-internal-dataset-laion2b-en/4.5v2-BLIP2/10m-subset-BLIP2v2/ \
    --bucket 1 \
    --wandb_name 256-512-bucket-BLIP2-genrun \
    --batch-size 128
